{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets -q\n",
    "# %pip install transformers -q\n",
    "# %pip install torch -q\n",
    "# %pip install seqeval -q\n",
    "# %pip install evaluate -q\n",
    "# %pip install accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetutils import decode\n",
    "from iob2converter import iob2_to_dataset\n",
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_ds = iob2_to_dataset(r'C:\\Users\\serru\\OneDrive\\Documents\\GitHub\\NLP\\TaggedSeparated\\French\\synopses_1.iob2')\n",
    "\n",
    "ner_feature_fr = fr_ds.features['ner_tags']\n",
    "label_names = ner_feature_fr.feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a bien longtemps dans une petite ville du bord de mer appellée Alto  Mare  vivait un vieux couple qui était seul sans enfant Un jour ils trouvirent 2 enfants un garçon et une fille Ce vieux couple aimait au plus profond leurs enfants et nauraient jamais souhaités les perdre Malheureusement un sombre nuage sinstalla sur Alto  Mare  pour des raisons inconnues La mère de ces deux enfants se promennaient avec eux en ville en direction de leur domicile quand soudain un éclair maléfique frappa la mère qui mourrut sur le coup Les deux enfants se mirent à pleurer leur mère et comme la légende le dit ça sest vu dans Pokémon 1 ou le retour de Mewtwo Les larmes venues du coeur ont des pouvoirs extraordinaires Juste après leur mort un second éclair frappa les deux enfants et furent eux aussi tués sur le coup Mais leur tristesse et leur larmes se mirent à former une sphère bleue  la Larme  venue du coeur Cette sphère aux pouvoirs magiques ressussita les deux enfants en Pokémon Latias et Latios \n",
      "O  O O O    O         O    O   O      O     O  O    O  O   O        B-PER I-PER O      O  O     O      O   O     O    O    O      O  O    O   O          O O       O  O      O  O   O     O  O     O      O      O  O    O       O     O       O  O         O      O         O   O      O               O  O      O     O         O   B-PER I-PER O    O   O       O         O  O    O  O   O    O       O  O            O    O   O  O     O  O         O  O    O        O     O       O  O      O         O      O  O    O   O       O   O  O    O   O    O       O  O      O O       O    O    O  O     O  O       O  O   O  O    O  O    B-POK   O O  O  O      O  B-LOC  O   O      O      O  O     O   O   O        O               O     O     O    O    O  O      O      O      O   O    O       O  O      O   O     O    O   O  O    O    O    O         O  O    O      O  O      O O      O   B-MISC I-MISC O  B-MISC O     O  O     O     O      O   O        O        O          O   O    O       O  B-POK   B-POK  O  B-POK  \n"
     ]
    }
   ],
   "source": [
    "words = fr_ds[0]['tokens']\n",
    "labels = fr_ds[0]['ner_tags']\n",
    "print('\\n'.join(decode(words, labels, label_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = 'google-bert/bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    \"\"\"\n",
    "    This function aligns labels with tokens produced by the tokenizer.\n",
    "    - `-100` is used for special tokens to ignore them during training.\n",
    "    - If the label is B-XXX, subsequent sub-tokens receive I-XXX.\n",
    "    \"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            # Convert B-XXX to I-XXX for sub-tokens\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a44ae73e16544cd8f40c7966f5ac700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d098f8b9bdea4942bf3b004f81ddf664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, Features, Sequence, ClassLabel, Value\n",
    "\n",
    "def iob2_to_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Converts an IOB2 file into a DatasetDict with train and validation splits.\n",
    "    Assumes the input file uses whitespace to separate tokens and tags, and that each sentence is separated by a blank line.\n",
    "    \"\"\"\n",
    "    tokens, ner_tags = [], []\n",
    "    sentences, sentence_tags = [], []\n",
    "\n",
    "    label_set = set()\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if tokens and ner_tags:\n",
    "                    sentences.append(tokens)\n",
    "                    sentence_tags.append(ner_tags)\n",
    "                tokens, ner_tags = [], []\n",
    "            else:\n",
    "                word, tag = line.split()\n",
    "                tokens.append(word)\n",
    "                ner_tags.append(tag)\n",
    "                label_set.add(tag)\n",
    "\n",
    "        if tokens and ner_tags:\n",
    "            sentences.append(tokens)\n",
    "            sentence_tags.append(ner_tags)\n",
    "\n",
    "    label_list = sorted(label_set)\n",
    "    label_mapping = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    indexed_tags = [[label_mapping[tag] for tag in tags] for tags in sentence_tags]\n",
    "    dataset = Dataset.from_dict({\"tokens\": sentences, \"ner_tags\": indexed_tags})\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    datasets = dataset.train_test_split(train_size=train_size)\n",
    "\n",
    "    features = Features({\n",
    "        \"tokens\": Sequence(Value(\"string\")),\n",
    "        \"ner_tags\": Sequence(ClassLabel(names=label_list))\n",
    "    })\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": datasets[\"train\"].cast(features),\n",
    "        \"validation\": datasets[\"test\"].cast(features)\n",
    "    })\n",
    "\n",
    "    return datasets\n",
    "\n",
    "file_path = r'C:\\Users\\serru\\OneDrive\\Documents\\GitHub\\NLP\\TaggedSeparated\\French\\synopses_1.iob2'\n",
    "fr_ds = iob2_to_dataset(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id, num_labels=len(label_names)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39709107f8b495bbe300b8441200fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9018c29e0bb43ccb8b540b6bfd00654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = fr_ds.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "print(tokenized_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dans', 'le', 'Royaume', 'des', 'Diamants', 'souterrain', 'où', 'de', 'nombreux', 'Strassie', 'vivent', 'le', 'Pokémon', 'fabuleux', 'Diancie', 'en', 'est', 'le', 'chef', 'Le', 'Cœur', 'de', 'Diamant', 'qui', 'assure', 'la', 'pérennité', 'du', 'royaume', 'séteint', 'peu', 'à', 'peu', 'et', 'Diancie', 'nest', 'pas', 'encore', 'suffisamment', 'forte', 'pour', 'en', 'créer', 'un', 'nouveau', 'Alors', 'quelle', 'recherche', 'laide', 'du', 'Pokémon', 'légendaire', 'Xerneas', 'Diancie', 'rencontre', 'un', 'groupe', 'de', 'voleurs', 'voulant', 'sapproprier', 'sa', 'capacité', 'à', 'créer', 'des', 'diamants', 'et', 'qui', 'par', 'la', 'même', 'occasion', 'réveillent', 'le', 'Pokémon', 'légendaire', 'Yveltal', 'et', 'le', 'tirent', 'de', 'son', 'cocon', 'Sacha', 'et', 'ses', 'amis', 'vontils', 'parvenir', 'à', 'aider', 'Diancie', 'à', 'découvrir', 'son', 'vrai', 'pouvoir', 'arrêter', 'la', 'rage', 'destructive', 'dYveltal', 'et', 'sauver', 'le', 'Royaume', 'des', 'Diamants']\n",
      "[-100, 9, 9, 0, 5, 5, 6, 6, 5, 6, 6, 9, 9, 9, 4, 4, 4, 9, 9, 4, 9, 10, 10, 4, 4, 4, 9, 9, 9, 9, 9, 1, 9, 6, 6, 9, 9, 9, 9, 10, 10, 9, 9, 9, 10, 10, 9, 9, 9, 9, 4, 4, 4, 9, 9, 9, 9, 10, 10, 10, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 9, 4, 9, 10, 10, 10, 1, 2, 2, 4, 4, 4, 9, 9, 9, 9, 9, 10, 9, 10, 9, 10, 10, 10, 9, 9, 9, 9, 9, 9, 10, 10, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 9, 4, 9, 10, 10, 10, 0, 0, 0, 9, 9, 9, 10, -100]\n",
      "\n",
      "['Koko', 'grandit', 'dans', 'la', 'jungle', 'avec', 'un', 'Zarude', 'solitaire', 'En', 'rencontrant', 'Sacha', 'et', 'Pikachu', 'il', 'découvre', 'le', 'monde', 'des', 'humains', 'et', 'apprend', 'que', 'son', 'environnement', 'est', 'menacé']\n",
      "[-100, 3, 4, 9, 10, 9, 9, 9, 9, 9, 4, 4, 9, 10, 9, 9, 10, 10, 3, 9, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_ds['train']['tokens'][i])\n",
    "    print(tokenized_ds['train']['labels'][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained (\n",
    "    model_id,\n",
    "    num_labels=len(label_names),\n",
    "    id2label={id: label for id, label in enumerate(label_names)},\n",
    "    label2id={label: id for id, label in enumerate(label_names)},\n",
    ")\n",
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a203eaf97dd4f7f8c246c26f15b95c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5409ad22e34788ad627f1591ec119b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: - seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.135202407836914, 'eval_precision': 0.4230769230769231, 'eval_recall': 0.55, 'eval_f1': 0.47826086956521735, 'eval_accuracy': 0.4948453608247423, 'eval_runtime': 0.8062, 'eval_samples_per_second': 2.481, 'eval_steps_per_second': 1.24, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874460d74e324096b2b5ee7693ec5cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7529469728469849, 'eval_precision': 0.5, 'eval_recall': 0.6928571428571428, 'eval_f1': 0.5808383233532934, 'eval_accuracy': 0.6082474226804123, 'eval_runtime': 0.7561, 'eval_samples_per_second': 2.645, 'eval_steps_per_second': 1.322, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4c45ff5576445babcfb87b776a5384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serru\\.conda\\envs\\New\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6290361881256104, 'eval_precision': 0.5051546391752577, 'eval_recall': 0.7, 'eval_f1': 0.5868263473053892, 'eval_accuracy': 0.6134020618556701, 'eval_runtime': 0.8089, 'eval_samples_per_second': 2.472, 'eval_steps_per_second': 1.236, 'epoch': 3.0}\n",
      "{'train_runtime': 57.8894, 'train_samples_per_second': 0.259, 'train_steps_per_second': 0.052, 'train_loss': 2.0811095237731934, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=2.0811095237731934, metrics={'train_runtime': 57.8894, 'train_samples_per_second': 0.259, 'train_steps_per_second': 0.052, 'train_loss': 2.0811095237731934, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"mbert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(r\"C:\\Users\\serru\\OneDrive\\Documents\\GitHub\\NLP\\TaggedSeparated\\French\\ModelS1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
