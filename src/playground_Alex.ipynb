{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets -q\n",
    "# %pip install transformers -q\n",
    "# %pip install torch -q\n",
    "# %pip install seqeval -q\n",
    "# %pip install evaluate -q\n",
    "# %pip install accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(words, labels, label_names):\n",
    "\tline1 = ''\n",
    "\tline2 = ''\n",
    "\tfor word, label in zip(words, labels):\n",
    "\t\tfull_label = label_names[label]\n",
    "\t\tmax_length = max(len(word), len(full_label))\n",
    "\t\tline1 += word + ' ' * (max_length - len(word) + 1)\n",
    "\t\tline2 += full_label + ' ' * (max_length - len(full_label) + 1)\n",
    "\n",
    "\treturn line1, line2\n",
    "\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "\tnew_labels = []\n",
    "\tcurrent_word = None\n",
    "\tfor word_id in word_ids:\n",
    "\t\tif word_id != current_word:\n",
    "\t\t\t# Start of a new word!\n",
    "\t\t\tcurrent_word = word_id\n",
    "\t\t\tlabel = -100 if word_id is None else labels[word_id]\n",
    "\t\t\tnew_labels.append(label)\n",
    "\t\telif word_id is None:\n",
    "\t\t\t# Special token\n",
    "\t\t\tnew_labels.append(-100)\n",
    "\t\telse:\n",
    "\t\t\t# Same word as previous token\n",
    "\t\t\tlabel = labels[word_id]\n",
    "\t\t\t# If the label is B-XXX we change it to I-XXX\n",
    "\t\t\tif label % 2 == 1:\n",
    "\t\t\t\tlabel += 1\n",
    "\t\t\tnew_labels.append(label)\n",
    "\n",
    "\treturn new_labels\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples, tokenizer):\n",
    "\ttokenized_inputs = tokenizer(\n",
    "\t\texamples['tokens'], truncation=True, is_split_into_words=True\n",
    "\t)\n",
    "\tall_labels = examples['ner_tags']\n",
    "\tnew_labels = []\n",
    "\tfor i, labels in enumerate(all_labels):\n",
    "\t\tword_ids = tokenized_inputs.word_ids(i)\n",
    "\t\tnew_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "\ttokenized_inputs['labels'] = new_labels\n",
    "\treturn tokenized_inputs\n",
    "\n",
    "from datasets import ClassLabel, Dataset, Features, Sequence, Value\n",
    "\n",
    "tag_to_id = {\n",
    "\t'O': 0,\n",
    "\t'B-PER': 1,\n",
    "\t'I-PER': 2,\n",
    "\t'B-ORG': 3,\n",
    "\t'I-ORG': 4,\n",
    "\t'B-LOC': 5,\n",
    "\t'I-LOC': 6,\n",
    "\t'B-MISC': 7,\n",
    "\t'I-MISC': 8,\n",
    "\t'B-POK': 9,\n",
    "\t'I-POK': 10,\n",
    "}\n",
    "id_to_tag = {id: tag for tag, id in tag_to_id.items()}\n",
    "\n",
    "\n",
    "def iob2_to_dataset(fp):\n",
    "\t\"\"\"Converts an iob2 file to a huggingface dataset.\n",
    "\tfp: path to the iob2 file.\"\"\"\n",
    "\twith open(fp, encoding='utf-8') as f:\n",
    "\t\traw_data = f.readlines()\n",
    "\n",
    "\tdata = {'tokens': [], 'ner_tags': [], 'ner_tags_id': [], 'index': [], 'id': []}\n",
    "\tcurrent = {'tokens': [], 'ner_tags': [], 'ner_tags_id': [], 'index': []}\n",
    "\tsentence_idx = 0\n",
    "\tword_idx = 0\n",
    "\tfor line_idx, line in enumerate(raw_data):\n",
    "\t\tif line.startswith('#'):\n",
    "\t\t\tcontinue\n",
    "\t\tif line == '\\n':  # new sentence\n",
    "\t\t\tdata['tokens'].append(current['tokens'])\n",
    "\t\t\tdata['ner_tags'].append(current['ner_tags'])\n",
    "\t\t\tdata['ner_tags_id'].append(current['ner_tags_id'])\n",
    "\t\t\tdata['index'].append(current['index'])\n",
    "\t\t\tdata['id'].append(str(sentence_idx))\n",
    "\t\t\tcurrent = {'tokens': [], 'ner_tags': [], 'ner_tags_id': [], 'index': []}\n",
    "\t\t\tsentence_idx += 1\n",
    "\t\t\tword_idx = 0\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tword, ner_tag = line.split()\n",
    "\t\texcept ValueError:\n",
    "\t\t\traise ValueError(f'Invalid line: {line} at line {line_idx+1}')\n",
    "\t\tcurrent['tokens'].append(word)\n",
    "\t\tcurrent['ner_tags'].append(ner_tag)\n",
    "\t\ttry:\n",
    "\t\t\tcurrent['ner_tags_id'].append(tag_to_id[ner_tag])\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise ValueError(\n",
    "\t\t\t\tf'Invalid tag: {ner_tag}. Valid tags are: {list(tag_to_id.keys())}'\n",
    "\t\t\t)\n",
    "\t\tcurrent['index'].append(word_idx)\n",
    "\t\tword_idx += 1\n",
    "\t# the file does not end in a newline, so we need to append the last sentence\n",
    "\tif word_idx != 0:\n",
    "\t\tdata['tokens'].append(current['tokens'])\n",
    "\t\tdata['ner_tags'].append(current['ner_tags'])\n",
    "\t\tdata['ner_tags_id'].append(current['ner_tags_id'])\n",
    "\t\tdata['index'].append(current['index'])\n",
    "\t\tdata['id'].append(str(sentence_idx))\n",
    "\n",
    "\tfeatures = Features(\n",
    "\t\t{\n",
    "\t\t\t'id': Value('string'),\n",
    "\t\t\t'tokens': Sequence(Value('string')),\n",
    "\t\t\t'ner_tags': Sequence(ClassLabel(names=list(tag_to_id.keys()))),\n",
    "\t\t\t'ner_tags_id': Sequence(Value('int32')),\n",
    "\t\t\t'index': Sequence(Value('int32')),\n",
    "\t\t}\n",
    "\t)\n",
    "\tdataset_raw = Dataset.from_dict(data, features=features)\n",
    "\treturn dataset_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasetutils import decode\n",
    "# from iob2converter import iob2_to_dataset\n",
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC', 'B-POK', 'I-POK']\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/TaggedSeparated/german/0.iob2'\n",
    "\n",
    "de_ds = iob2_to_dataset(file_path)\n",
    "\n",
    "ner_feature_fr = de_ds.features['ner_tags']\n",
    "label_names = ner_feature_fr.feature.names\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ash   Pikachu und der Rest der Gang sehen ihre größte Herausforderung entgegen als zwei hinterlistige Diebinnen den geheimnisvollsten und gefährlichsten aller Kristalle Herztropfen rauben wollen Fällt er in ihre Hände ist die Zerstörung der Wasserstadt Altomare unvermeidbar Es beginnt ein atemberaubendes Rennen gegen die Zeit bei dem die letzte Hoffnung auf Latios und Latias ruht die als Hüter des Kristalls mit magischen Kräften ausgestattet sind \n",
      "B-PER B-POK   O   O   O    O   O    O     O    O      O               O        O   O    O             O         O   O                 O   O              O     O         O           O      O      O     O  O  O    O     O   O   O          O   B-LOC       I-LOC    O            O  O       O   O               O      O     O   O    O   O   O   O      O        O   B-POK  O   B-POK  O    O   O   O     O   O         O   O         O       O            O    \n"
     ]
    }
   ],
   "source": [
    "words = de_ds[0]['tokens']\n",
    "labels = de_ds[0]['ner_tags']\n",
    "print('\\n'.join(decode(words, labels, label_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = 'google-bert/bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=128,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    \"\"\"\n",
    "    This function aligns labels with tokens produced by the tokenizer.\n",
    "    - `-100` is used for special tokens to ignore them during training.\n",
    "    - If the label is B-XXX, subsequent sub-tokens receive I-XXX.\n",
    "    \"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            # Convert B-XXX to I-XXX for sub-tokens\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id, num_labels=len(label_names)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ac7971306f434a9e488e4020c531c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tokens', 'ner_tags', 'ner_tags_id', 'index', 'id', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = de_ds.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "print(tokenized_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rob span-f1 \n",
    "\n",
    "def toSpans(tags):\n",
    "    spans = set()\n",
    "    for beg in range(len(tags)):\n",
    "        if tags[beg][0] == 'B':\n",
    "            end = beg\n",
    "            for end in range(beg+1, len(tags)):\n",
    "                if tags[end][0] != 'I':\n",
    "                    break\n",
    "            spans.add(str(beg) + '-' + str(end) + ':' + tags[beg][2:])\n",
    "    return spans\n",
    "\n",
    "\n",
    "def getInstanceScores(predSpans, goldSpans):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    overlap = len(goldSpans.intersection(predSpans))\n",
    "    tp += overlap\n",
    "    fp += len(predSpans) - overlap\n",
    "    fn += len(goldSpans) - overlap\n",
    "        \n",
    "    prec = 0.0 if tp+fp == 0 else tp/(tp+fp)\n",
    "    rec = 0.0 if tp+fn == 0 else tp/(tp+fn)\n",
    "    f1 = 0.0 if prec+rec == 0.0 else 2 * (prec * rec) / (prec + rec)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    pred_spans, true_spans = toSpans(true_predictions[0]), toSpans(true_labels[0])\n",
    "    score = getInstanceScores(pred_spans, true_spans)\n",
    "\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "        \"span_f1\": score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained (\n",
    "    model_id,\n",
    "    num_labels=len(label_names),\n",
    "    id2label={id: label for id, label in enumerate(label_names)},\n",
    "    label2id={label: id for id, label in enumerate(label_names)},\n",
    ").to(device)\n",
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"mbert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    # remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=tokenized_ds[\"train\"],\n",
    "#     eval_dataset=tokenized_ds[\"validation\"],\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Dataset, Features, Sequence, Value\n",
    "\n",
    "tag_to_id = {\n",
    "\t'O': 0,\n",
    "\t'B-PER': 1,\n",
    "\t'I-PER': 2,\n",
    "\t'B-ORG': 3,\n",
    "\t'I-ORG': 4,\n",
    "\t'B-LOC': 5,\n",
    "\t'I-LOC': 6,\n",
    "\t'B-MISC': 7,\n",
    "\t'I-MISC': 8,\n",
    "\t'B-POK': 9,\n",
    "\t'I-POK': 10,\n",
    "}\n",
    "id_to_tag = {id: tag for tag, id in tag_to_id.items()}\n",
    "\n",
    "\n",
    "def iob2_to_dataset(fp):\n",
    "\t\"\"\"Converts an iob2 file to a huggingface dataset.\n",
    "\tfp: path to the iob2 file.\"\"\"\n",
    "\twith open(fp, encoding='utf-8') as f:\n",
    "\t\traw_data = f.readlines()\n",
    "\n",
    "\tdata = {'tokens': [], 'ner_tags': [], 'ner_tags_id': [], 'index': [], 'id': []}\n",
    "\tcurrent = {'tokens': [], 'ner_tags': [], 'ner_tags_id': [], 'index': []}\n",
    "\tsentence_idx = 0\n",
    "\tword_idx = 0\n",
    "\tfor line_idx, line in enumerate(raw_data):\n",
    "\t\tif line.startswith('#'):\n",
    "\t\t\tcontinue\n",
    "\t\tif line == '\\n':  # new sentence\n",
    "\t\t\tdata['tokens'].append(current['tokens'])\n",
    "\t\t\tdata['ner_tags'].append(current['ner_tags'])\n",
    "\t\t\tdata['ner_tags_id'].append(current['ner_tags_id'])\n",
    "\t\t\tdata['index'].append(current['index'])\n",
    "\t\t\tdata['id'].append(str(sentence_idx))\n",
    "\t\t\tcurrent = {'tokens': [], 'ner_tags': [], 'ner_tags_id': [], 'index': []}\n",
    "\t\t\tsentence_idx += 1\n",
    "\t\t\tword_idx = 0\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tword, ner_tag = line.split()\n",
    "\t\texcept ValueError:\n",
    "\t\t\traise ValueError(f'Invalid line: {line} at line {line_idx+1}')\n",
    "\t\tcurrent['tokens'].append(word)\n",
    "\t\tcurrent['ner_tags'].append(ner_tag)\n",
    "\t\ttry:\n",
    "\t\t\tcurrent['ner_tags_id'].append(tag_to_id[ner_tag])\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise ValueError(\n",
    "\t\t\t\tf'Invalid tag: {ner_tag}. Valid tags are: {list(tag_to_id.keys())}'\n",
    "\t\t\t)\n",
    "\t\tcurrent['index'].append(word_idx)\n",
    "\t\tword_idx += 1\n",
    "\t# the file does not end in a newline, so we need to append the last sentence\n",
    "\tif word_idx != 0:\n",
    "\t\tdata['tokens'].append(current['tokens'])\n",
    "\t\tdata['ner_tags'].append(current['ner_tags'])\n",
    "\t\tdata['ner_tags_id'].append(current['ner_tags_id'])\n",
    "\t\tdata['index'].append(current['index'])\n",
    "\t\tdata['id'].append(str(sentence_idx))\n",
    "\n",
    "\tfeatures = Features(\n",
    "\t\t{\n",
    "\t\t\t'id': Value('string'),\n",
    "\t\t\t'tokens': Sequence(Value('string')),\n",
    "\t\t\t'ner_tags': Sequence(ClassLabel(names=list(tag_to_id.keys()))),\n",
    "\t\t\t'ner_tags_id': Sequence(Value('int32')),\n",
    "\t\t\t'index': Sequence(Value('int32')),\n",
    "\t\t}\n",
    "\t)\n",
    "\tdataset_raw = Dataset.from_dict(data, features=features)\n",
    "\treturn dataset_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, Features, Sequence, ClassLabel, Value\n",
    "\n",
    "tag_to_id = {\n",
    "\t'O': 0,\n",
    "\t'B-PER': 1,\n",
    "\t'I-PER': 2,\n",
    "\t'B-ORG': 3,\n",
    "\t'I-ORG': 4,\n",
    "\t'B-LOC': 5,\n",
    "\t'I-LOC': 6,\n",
    "\t'B-MISC': 7,\n",
    "\t'I-MISC': 8,\n",
    "\t'B-POK': 9,\n",
    "\t'I-POK': 10,\n",
    "}\n",
    "id_to_tag = {id: tag for tag, id in tag_to_id.items()}\n",
    "\n",
    "def iob2s_to_datasets(file_paths, reference_path):\n",
    "    \"\"\"\n",
    "    Converts an IOB2 file into a DatasetDict with train and validation splits.\n",
    "    Assumes the input file uses whitespace to separate tokens and tags, and that each sentence is separated by a blank line.\n",
    "    \"\"\"\n",
    "    tokens, ner_tags = [], []\n",
    "    sentences, sentence_tags = [], []\n",
    "\n",
    "    label_set = set()\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    if tokens and ner_tags:\n",
    "                        sentences.append(tokens)\n",
    "                        sentence_tags.append(ner_tags)\n",
    "                    tokens, ner_tags = [], []\n",
    "                else:\n",
    "                    try:\n",
    "                        word, tag = line.split()\n",
    "                    except:\n",
    "                        raise ValueError(f\"Each line must have two columns: ({i}) {line}\")\n",
    "                    tokens.append(word)\n",
    "                    ner_tags.append(tag)\n",
    "                    label_set.add(tag)\n",
    "\n",
    "            if tokens and ner_tags:\n",
    "                sentences.append(tokens)\n",
    "                sentence_tags.append(ner_tags)\n",
    "\n",
    "    label_list = list(tag_to_id.keys())\n",
    "    label_mapping = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    indexed_tags = [[label_mapping[tag] for tag in tags] for tags in sentence_tags]\n",
    "    dataset = Dataset.from_dict({\"tokens\": sentences, \"ner_tags\": indexed_tags})\n",
    "    reference_german = iob2_to_dataset(reference_path[0]).remove_columns([\"ner_tags_id\", \"index\", \"id\"])\n",
    "    reference_french = iob2_to_dataset(reference_path[1]).remove_columns([\"ner_tags_id\", \"index\", \"id\"])\n",
    "    reference_english = iob2_to_dataset(reference_path[2]).remove_columns([\"ner_tags_id\", \"index\", \"id\"])\n",
    "    \n",
    "\n",
    "    features = Features({\n",
    "        \"tokens\": Sequence(Value(\"string\")),\n",
    "        \"ner_tags\": Sequence(ClassLabel(names=label_list))\n",
    "    })\n",
    "\n",
    "    datasets = DatasetDict({\n",
    "        \"train\": dataset.cast(features),\n",
    "        \"val_de\": reference_german.cast(features),\n",
    "        \"val_fr\": reference_french.cast(features),\n",
    "        \"val_en\": reference_english.cast(features),\n",
    "    })\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437c60d4d5c04257afcd203a743c4fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01092281d994fad9f59d11dcdf32475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4a48b053b04e828d2139be2ca997d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c3c9eb9ea04ac485d7a9604bdd887b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bee7a4053f413b85895ca9853035dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5374d87f71344ee5a622d48bfff815c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aea479e34fa4be5940cf15b186ea678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915d966e4c644fb59f8bad8c1772367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 56\u001b[0m\n\u001b[1;32m     46\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m tokenized_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m lang]\n\u001b[1;32m     48\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     49\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     50\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m res_de \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(tokenized_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_de\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[1;32m     59\u001b[0m res_fr \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(tokenized_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_fr\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/transformers/trainer.py:2165\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2162\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2165\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/accelerate/data_loader.py:451\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/transformers/data/data_collator.py:92\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[0;34m(features, return_tensors)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# have the same attributes.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# on the whole batch.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_default_data_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "File \u001b[0;32m/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/transformers/data/data_collator.py:158\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    156\u001b[0m             batch[k] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mstack([f[k] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]))\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m             batch[k] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "llang = {\n",
    "    \"fr\": \"french\",\n",
    "    \"en\": \"english\",\n",
    "    \"de\": \"german\"\n",
    "}\n",
    "\n",
    "# - Load the iob2 files\n",
    "# - For each language:\n",
    "#   - 5 times:\n",
    "#     - For i = 1..len(files):\n",
    "#       - Choose i random files and concat them.\n",
    "#       - Train the model on the concatenated files.\n",
    "#       - Evaluate the model on reference texts.\n",
    "#     - Average the results and store them in a dataframe.\n",
    "# - Save the dataframe as a tsv file.\n",
    "\n",
    "ITERATIONS = 5\n",
    "\n",
    "referenceFiles = {\n",
    "    \"fr\": './ReferenceText/ReferenceTextFrench.iob2',\n",
    "    \"en\": './ReferenceText/ReferenceTextEnglish.iob2',\n",
    "    \"de\": './ReferenceText/ReferenceTextGerman.iob2'\n",
    "}\n",
    "\n",
    "for lang, language in llang.items():\n",
    "    files = os.listdir('./data/TaggedSeparated/' + language)\n",
    "    for i in range(len(files)):\n",
    "        df = pd.DataFrame(columns=[\"precision\", \"recall\", \"f1\", \"accuracy\", \"span_f1\"])\n",
    "\n",
    "        for it in range(ITERATIONS):\n",
    "            train_files = np.random.choice(files, i+1, replace=False)\n",
    "            train_files_paths = ['./data/TaggedSeparated/' + language + '/' + f for f in train_files]\n",
    "            datasets = iob2s_to_datasets(train_files_paths, list(referenceFiles.values()))\n",
    "            tokenized_ds = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "            \n",
    "            model = AutoModelForTokenClassification.from_pretrained(\n",
    "                model_id, num_labels=len(label_names)\n",
    "            ).to(device)\n",
    "            \n",
    "            \n",
    "            train_dataset = tokenized_ds[\"train\"]\n",
    "            eval_dataset = tokenized_ds[\"val_\" + lang]\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "\n",
    "            trainer.train()\n",
    "\n",
    "            res_de = trainer.predict(tokenized_ds[\"val_de\"]).metrics\n",
    "            res_fr = trainer.predict(tokenized_ds[\"val_fr\"]).metrics\n",
    "            res_en = trainer.predict(tokenized_ds[\"val_en\"]).metrics\n",
    "            df.loc[-1] = [res_de[\"precision\"], res_de[\"recall\"], res_de[\"f1\"], res_de[\"accuracy\"], res_de[\"span_f1\"]]\n",
    "            df.index = df.index + 1\n",
    "            df = df.sort_index()\n",
    "            df.loc[-1] = [res_fr[\"precision\"], res_fr[\"recall\"], res_fr[\"f1\"], res_fr[\"accuracy\"], res_fr[\"span_f1\"]]\n",
    "            df.index = df.index + 1\n",
    "            df = df.sort_index()\n",
    "            df.loc[-1] = [res_en[\"precision\"], res_en[\"recall\"], res_en[\"f1\"], res_en[\"accuracy\"], res_en[\"span_f1\"]]\n",
    "            df.index = df.index + 1\n",
    "            df = df.sort_index()\n",
    "        \n",
    "        # average over all iterations\n",
    "        df = df.mean()\n",
    "        print(df)\n",
    "        raise ValueError(\"Stop here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create new datframe for results.\n",
    "# df = pd.DataFrame(columns=[\"train_lang\", \"train_file\", \"test_lang\", \"precision\", \"recall\", \"f1\", \"accuracy\", \"span_f1\"])\n",
    "# for lang in [\"fr\", \"en\", \"de\"]:\n",
    "\n",
    "#     def fine_tune_models_in_folder(folder_path, output_dir):\n",
    "#         files = os.listdir(folder_path)\n",
    "        \n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "#             data = iob2_to_datasets(file_path, reference_grp_path)\n",
    "            \n",
    "#             tokenized_ds = data.map(tokenize_and_align_labels, batched=True)\n",
    "            \n",
    "#             model = AutoModelForTokenClassification.from_pretrained(\n",
    "#                 model_id, num_labels=len(label_names)\n",
    "#             ).to(device)\n",
    "            \n",
    "#             trainer = Trainer(\n",
    "#                 model=model,\n",
    "#                 args=args,\n",
    "#                 train_dataset=tokenized_ds[\"train\"],\n",
    "#                 eval_dataset=tokenized_ds[\"val_\" + lang],\n",
    "#                 compute_metrics=compute_metrics,\n",
    "\n",
    "#             )\n",
    "\n",
    "#             trainer.train()\n",
    "\n",
    "#             res_de = trainer.predict(tokenized_ds[\"val_de\"]).metrics\n",
    "#             res_fr = trainer.predict(tokenized_ds[\"val_fr\"]).metrics\n",
    "#             res_en = trainer.predict(tokenized_ds[\"val_en\"]).metrics\n",
    "\n",
    "#             print (res_de)\n",
    "\n",
    "#             # Append result to dataframe\n",
    "#             df.loc[-1] = [\n",
    "#                 llang[lang],\n",
    "#                 file,\n",
    "#                 \"german\",\n",
    "#                 res_de[\"test_precision\"],\n",
    "#                 res_de[\"test_recall\"],\n",
    "#                 res_de[\"test_f1\"],\n",
    "#                 res_de[\"test_accuracy\"],\n",
    "#                 res_de[\"test_span_f1\"]\n",
    "#             ]\n",
    "#             df.index = df.index + 1\n",
    "#             df.loc[-1] = [\n",
    "#                 llang[lang],\n",
    "#                 file,\n",
    "#                 \"french\",\n",
    "#                 res_fr[\"test_precision\"],\n",
    "#                 res_fr[\"test_recall\"],\n",
    "#                 res_fr[\"test_f1\"],\n",
    "#                 res_fr[\"test_accuracy\"],\n",
    "#                 res_fr[\"test_span_f1\"]\n",
    "#             ]\n",
    "#             df.index = df.index + 1\n",
    "#             df.loc[-1] = [\n",
    "#                 llang[lang],\n",
    "#                 file,\n",
    "#                 \"english\",\n",
    "#                 res_en[\"test_precision\"],\n",
    "#                 res_en[\"test_recall\"],\n",
    "#                 res_en[\"test_f1\"],\n",
    "#                 res_en[\"test_accuracy\"],\n",
    "#                 res_en[\"test_span_f1\"]\n",
    "#             ]\n",
    "#             df.index = df.index + 1\n",
    "\n",
    "#     folder_path = '../data/TaggedSeparated/' + llang[lang]\n",
    "#     output_dir = '../Models/m_' + lang\n",
    "\n",
    "#     fine_tune_models_in_folder(folder_path, output_dir)\n",
    "\n",
    "# # Save dataframe as tsv\n",
    "# df.to_csv('results.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cff9be38e34e9ea8eb4d01c8f146eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a0493ca5e343c8a27a2b3e64db8631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8c9cca9f1542cf8ccf3245b5895d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9c95c8e6714835bb19ec95850b054b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620dae0f6d9c4f9994b9d5d74e406b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a33d64d93774706af85f37634aee18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f15e16d47124f0f9dae0e95ddac80f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364830a0cdcf4023b6e80e64081c8397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I-PER', 'I-PER', 'I-POK', 'I-PER', 'I-PER', 'I-POK', 'I-PER', 'I-ORG', 'I-POK', 'I-PER', 'I-ORG', 'I-ORG', 'I-POK', 'I-ORG', 'I-POK', 'I-ORG', 'I-ORG', 'I-MISC', 'I-MISC', 'B-LOC', 'I-ORG', 'I-MISC', 'I-ORG', 'B-LOC', 'I-POK', 'I-ORG', 'I-PER', 'I-ORG', 'B-LOC', 'I-ORG', 'I-MISC', 'B-ORG', 'I-MISC', 'I-ORG', 'I-ORG', 'I-MISC', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-POK', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'B-LOC', 'B-LOC', 'I-ORG', 'I-MISC', 'I-POK', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-PER', 'I-PER', 'I-PER', 'B-LOC', 'I-PER', 'I-ORG', 'I-POK', 'B-ORG', 'I-POK', 'B-LOC', 'I-ORG', 'I-ORG', 'I-ORG', 'B-LOC', 'B-LOC', 'I-ORG', 'I-PER', 'B-LOC', 'I-MISC', 'I-ORG', 'B-LOC', 'I-PER', 'I-PER', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-MISC', 'I-MISC', 'I-ORG', 'I-MISC', 'I-MISC', 'I-PER', 'I-ORG', 'I-ORG', 'I-ORG', 'I-POK', 'B-LOC', 'I-ORG', 'I-ORG', 'I-MISC', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-MISC', 'B-ORG', 'I-MISC', 'I-MISC', 'I-MISC', 'I-PER', 'B-POK', 'I-ORG', 'B-POK', 'B-LOC', 'B-LOC', 'B-POK']] [['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POK', 'I-POK', 'B-POK', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "{'87-105:LOC', '84-87:LOC', '120-122:POK', '125-125:POK', '52-53:LOC', '122-123:POK', '74-76:ORG', '105-115:LOC', '81-84:LOC', '23-28:LOC', '31-52:ORG', '80-81:LOC', '123-124:LOC', '28-31:LOC', '115-120:ORG', '53-70:LOC', '124-125:LOC', '76-80:LOC', '19-23:LOC', '70-74:LOC'} {'36-38:POK', '48-49:PER', '11-12:PER', '6-8:LOC', '115-120:POK', '102-103:PER', '38-39:POK'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/2pg80is2n7xidd110vbkgai325b4hxwg-python3-3.11.9-env/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-ORG', 'B-MISC', 'I-ORG', 'I-PER', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-PER', 'I-PER', 'B-LOC', 'I-POK', 'I-PER', 'B-LOC', 'B-POK', 'I-POK', 'I-POK', 'I-POK', 'I-PER', 'I-MISC', 'I-PER', 'I-MISC', 'B-LOC', 'I-ORG', 'I-ORG', 'I-POK', 'I-ORG', 'I-ORG', 'I-POK', 'I-ORG', 'I-PER', 'I-ORG', 'I-ORG', 'B-ORG', 'I-MISC', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'B-ORG', 'I-MISC', 'I-ORG', 'I-POK', 'I-MISC', 'I-ORG', 'I-ORG', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-MISC', 'I-ORG', 'I-ORG', 'I-ORG', 'I-PER', 'I-PER', 'I-POK', 'I-POK', 'I-PER', 'I-ORG', 'I-ORG', 'I-POK', 'I-POK', 'B-POK', 'I-POK', 'I-POK', 'I-POK', 'I-PER', 'I-PER', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'I-PER', 'I-PER', 'I-PER', 'I-POK', 'I-ORG', 'I-POK', 'I-PER', 'I-POK', 'I-MISC', 'B-POK', 'I-POK', 'I-POK', 'I-PER', 'B-POK', 'I-PER', 'I-PER', 'I-PER', 'I-MISC', 'I-ORG', 'I-ORG', 'I-MISC', 'I-MISC', 'I-PER', 'B-POK', 'I-POK', 'I-PER', 'I-POK', 'I-PER', 'I-ORG', 'I-ORG', 'I-POK']] [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POK', 'B-POK', 'I-POK', 'I-POK', 'I-POK', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
      "{'9-19:MISC', '19-22:LOC', '31-42:LOC', '118-125:POK', '81-104:POK', '42-49:ORG', '49-81:ORG', '104-108:POK', '22-23:LOC', '23-31:POK', '108-118:POK'} {'39-43:POK', '111-112:PER', '11-12:PER', '54-55:PER', '7-9:LOC', '38-39:POK'}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I-MISC', 'I-POK', 'I-PER', 'B-LOC', 'I-MISC', 'I-MISC', 'I-PER', 'I-ORG', 'I-MISC', 'I-MISC', 'I-MISC', 'I-POK', 'I-MISC', 'B-ORG', 'O', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'I-MISC', 'B-ORG', 'I-POK', 'I-PER', 'I-MISC', 'I-ORG', 'I-PER', 'I-ORG', 'B-MISC', 'I-ORG', 'I-ORG', 'I-MISC', 'I-ORG', 'I-ORG', 'I-ORG', 'I-MISC', 'I-MISC', 'I-ORG', 'B-LOC', 'I-POK', 'I-MISC', 'I-ORG', 'I-MISC', 'I-MISC', 'I-MISC', 'I-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-MISC', 'I-MISC', 'I-MISC', 'I-ORG', 'I-POK', 'I-PER', 'I-PER', 'I-LOC', 'I-POK', 'I-MISC', 'I-MISC', 'I-MISC', 'I-POK', 'I-PER', 'I-PER', 'I-POK', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-MISC', 'I-POK', 'I-POK', 'I-MISC', 'I-PER', 'I-POK', 'I-LOC', 'I-MISC', 'I-LOC', 'B-PER', 'I-POK', 'I-POK', 'I-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-LOC', 'I-POK', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-PER', 'I-POK', 'I-PER', 'I-PER', 'I-ORG', 'I-PER', 'I-MISC', 'I-ORG', 'I-MISC', 'I-PER', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-ORG']] [['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POK', 'B-POK', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-POK', 'I-POK', 'I-POK', 'I-POK', 'I-POK', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O']]\n",
      "{'13-14:ORG', '98-100:LOC', '36-43:ORG', '93-98:PER', '53-93:LOC', '43-53:MISC', '20-25:MISC', '100-125:LOC', '3-13:LOC'} {'31-32:POK', '30-31:POK', '91-96:POK', '122-123:PER', '9-10:PER', '103-104:PER', '6-8:LOC', '39-40:PER', '81-82:PER'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=[\"train_lang\", \"train_file\", \"test_lang\", \"precision\", \"recall\", \"f1\", \"accuracy\", \"span_f1\"])\n",
    "\n",
    "data = iob2_to_datasets(file_path, reference_grp_path)\n",
    "\n",
    "tokenized_ds = data.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id, num_labels=len(label_names)\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"val_\" + lang],\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ").to(device)\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "res_de = trainer.predict(tokenized_ds[\"val_de\"]).metrics\n",
    "res_fr = trainer.predict(tokenized_ds[\"val_fr\"]).metrics\n",
    "res_en = trainer.predict(tokenized_ds[\"val_en\"]).metrics\n",
    "\n",
    "df.loc[-1] = [\n",
    "    \"baseline\",\n",
    "    \"None\",\n",
    "    \"german\",\n",
    "    res_de[\"test_precision\"],\n",
    "    res_de[\"test_recall\"],\n",
    "    res_de[\"test_f1\"],\n",
    "    res_de[\"test_accuracy\"],\n",
    "    res_de[\"test_span_f1\"]\n",
    "]\n",
    "df.index = df.index + 1\n",
    "df.loc[-1] = [\n",
    "    \"baseline\",\n",
    "    \"None\",\n",
    "    \"french\",\n",
    "    res_fr[\"test_precision\"],\n",
    "    res_fr[\"test_recall\"],\n",
    "    res_fr[\"test_f1\"],\n",
    "    res_fr[\"test_accuracy\"],\n",
    "    res_fr[\"test_span_f1\"]\n",
    "]\n",
    "df.index = df.index + 1\n",
    "df.loc[-1] = [\n",
    "    \"baseline\",\n",
    "    \"None\",\n",
    "    \"english\",\n",
    "    res_en[\"test_precision\"],\n",
    "    res_en[\"test_recall\"],\n",
    "    res_en[\"test_f1\"],\n",
    "    res_en[\"test_accuracy\"],\n",
    "    res_en[\"test_span_f1\"]\n",
    "]\n",
    "df.index = df.index + 1\n",
    "\n",
    "\n",
    "# Save dataframe as tsv\n",
    "df.to_csv('results_baseline.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
